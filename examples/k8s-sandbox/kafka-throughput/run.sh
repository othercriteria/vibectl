#!/usr/bin/env bash
# Orchestrates the Kafka Throughput Demo using Docker Compose.

# Fail fast on any error
set -euo pipefail

echo "üîß Starting Kafka Throughput Demo Setup..."

# --- Configuration ---
# TODO: Add argument parsing for specific demo parameters if needed later.

# Check for VIBECTL_ANTHROPIC_API_KEY
if [ -z "${VIBECTL_ANTHROPIC_API_KEY:-}" ]; then
  echo "‚ùóÔ∏è VIBECTL_ANTHROPIC_API_KEY environment variable is not set."
  # Loop until a non-empty key is provided or the user cancels
  while [ -z "${VIBECTL_ANTHROPIC_API_KEY:-}" ]; do
    read -rsp "üîë Enter your Anthropic API key (starts with 'sk-ant-', press Enter to cancel): " key_input
    echo # Print a newline after the prompt
    if [ -z "$key_input" ]; then
      echo "‚ùå API key not provided. Exiting."
      exit 1
    fi
    # Basic check for the prefix
    if [[ "$key_input" == sk-ant-* ]]; then
      export VIBECTL_ANTHROPIC_API_KEY="$key_input"
      echo "‚úÖ API key accepted."
    else
      echo "‚ö†Ô∏è Invalid API key format. It should start with 'sk-ant-'. Please try again or press Enter to cancel."
    fi
  done
else
  echo "‚úÖ Using existing VIBECTL_ANTHROPIC_API_KEY from environment."
fi

# Detect Docker GID for container permissions
# Try getent first (Linux)
if command -v getent &> /dev/null && getent group docker &> /dev/null; then
    DOCKER_GID=$(getent group docker | cut -d: -f3)
# Try stat on the socket (macOS, other Linux)
elif command -v stat &> /dev/null && [ -S /var/run/docker.sock ]; then
    if stat -c '%g' /var/run/docker.sock &> /dev/null; then # Linux stat
        DOCKER_GID=$(stat -c '%g' /var/run/docker.sock)
    elif stat -f '%g' /var/run/docker.sock &> /dev/null; then # macOS stat
        DOCKER_GID=$(stat -f '%g' /var/run/docker.sock)
    fi
fi

# Default if detection failed or socket doesn't exist
if [ -z "${DOCKER_GID:-}" ]; then
    DOCKER_GID=999
    echo "‚ö†Ô∏è Could not detect Docker GID. Using default: ${DOCKER_GID}. File permissions inside containers might be affected."
else
    echo "üîç Detected Docker GID: ${DOCKER_GID}"
fi
export DOCKER_GID # Export GID for build --build-arg

# --- Generate Kafka Cluster ID (if needed) ---
STATUS_DIR="./status-volume"
ENV_FILE=".env.generated" # File for env vars for compose up
CLUSTER_ID_FILE="${STATUS_DIR}/kafka_cluster_id.txt"
GENERATED_KAFKA_CLUSTER_ID=""

# Ensure status directory exists (needed for storing the ID)
mkdir -p "${STATUS_DIR}"

if [ -f "${CLUSTER_ID_FILE}" ]; then
    GENERATED_KAFKA_CLUSTER_ID=$(cat "${CLUSTER_ID_FILE}")
    echo "üîë Using existing Kafka Cluster ID from ${CLUSTER_ID_FILE}: ${GENERATED_KAFKA_CLUSTER_ID}"
else
    echo "üîë Generating new Kafka Cluster ID..."
    # Use python to generate UUID reliably
    if command -v python3 &> /dev/null; then
        GENERATED_KAFKA_CLUSTER_ID=$(python3 -c "import uuid; print(uuid.uuid4())")
    elif command -v python &> /dev/null; then
         GENERATED_KAFKA_CLUSTER_ID=$(python -c "import uuid; print uuid.uuid4()") # Python 2 fallback
    else
        echo "‚ùå Error: Cannot generate UUID. Python 3 or Python not found." >&2
        exit 1
    fi

    if [ -z "${GENERATED_KAFKA_CLUSTER_ID}" ]; then
        echo "‚ùå Error: Failed to generate UUID using Python." >&2
        exit 1
    fi
    echo "${GENERATED_KAFKA_CLUSTER_ID}" > "${CLUSTER_ID_FILE}"
    echo "‚úÖ Generated and saved new Kafka Cluster ID: ${GENERATED_KAFKA_CLUSTER_ID}"
fi
export GENERATED_KAFKA_CLUSTER_ID # Export for compose file interpolation
# Write variables needed by compose up to the .env file
echo "Writing runtime env vars to ${ENV_FILE}..."
cat > "${ENV_FILE}" << EOF
# Generated by run.sh - DO NOT EDIT
DOCKER_GID=${DOCKER_GID}
GENERATED_KAFKA_CLUSTER_ID=${GENERATED_KAFKA_CLUSTER_ID}
EOF
# Ensure the file is readable
chmod 644 "${ENV_FILE}"

# --- Prerequisite Checks ---
echo "üßê Checking prerequisites..."

# Check for docker
if ! command -v docker &> /dev/null; then
    echo "‚ùå Error: 'docker' command not found. Please install Docker."
    exit 1
fi

# Check for docker compose (v1 or v2)
if command -v docker-compose &> /dev/null; then
    COMPOSE_CMD="docker-compose"
elif docker compose version &> /dev/null; then
    COMPOSE_CMD="docker compose"
else
    echo "‚ùå Error: 'docker-compose' or 'docker compose' command not found. Please install Docker Compose."
    exit 1
fi
echo "‚úÖ Docker and Docker Compose found ($COMPOSE_CMD)."

# Check docker socket permissions (optional check)
if [ -S /var/run/docker.sock ] && [ ! -r /var/run/docker.sock ] && [ ! -w /var/run/docker.sock ]; then
    echo "‚ö†Ô∏è Warning: Docker socket (/var/run/docker.sock) might not be readable/writable by the current user."
    echo "   You might need to run this script with sudo or add your user to the 'docker' group."
fi

# --- Cleanup Function ---
cleanup() {
  echo # Add a newline for clarity
  echo "üßπ Cleaning up Kafka Demo resources..."
  # Use the determined compose command
  # Use --project-name to avoid conflicts if needed, but compose.yml in dir should be sufficient
  # Use --timeout to prevent hanging
  # Suppress "network not found" errors etc. during down
  ${COMPOSE_CMD} -f compose.yml down --volumes --remove-orphans --timeout 30 2>/dev/null || true

  # Explicitly remove the shared volume just in case 'down --volumes' misses it
  # docker volume rm kafka-throughput_status-volume 2>/dev/null || true

  # Note: k3d cleanup is handled *inside* the k8s-sandbox container's entrypoint/trap

  echo "‚úÖ Cleanup attempt finished."
}

# --- Main Execution ---
echo "üöÄ Building and starting Docker containers..."

# Allow skipping startup if only build is requested
ONLY_BUILD=false
if [ "${1:-}" == "--build-only" ]; then
  ONLY_BUILD=true
fi

# Ensure we are in the script's directory to find compose.yml
cd "$(dirname "$0")"

# --- Step 1: Build Images ---
echo "üõ†Ô∏è Building Docker images..."
# Pass DOCKER_GID as a build argument
if ! ${COMPOSE_CMD} -f compose.yml build --build-arg DOCKER_GID=${DOCKER_GID}; then
    echo "‚ùå Error: Docker build failed." >&2
    exit 1 # Exit if build fails
fi
echo "‚úÖ Docker images built successfully."

# Exit here if only build was requested
if [ "${ONLY_BUILD}" = true ]; then
  echo "‚úÖ Build complete (--build-only requested)."
  exit 0
fi

# --- Step 2: Start Containers ---
echo "üö¢ Starting services..."
# Use the determined compose command
# Use --project-name to avoid conflicts if needed, but compose.yml in dir should be sufficient
# Use --env-file to pass the generated variables
if ! ${COMPOSE_CMD} -f compose.yml up -d; then
    echo "‚ùå Error: Docker compose up failed." >&2
    # Cleanup might already be triggered by failed container, but attempt explicit cleanup
    exit 1
fi

# --- Step 3: Wait for Kafka Readiness ---
echo "‚è≥ Waiting for the k8s-sandbox container to signal Kafka readiness..."
# This assumes the k8s-sandbox container creates this file when ready
# Path relative to the script's directory (examples/k8s-sandbox/kafka-throughput/)
status_file_path="${STATUS_DIR}/kafka_ready"
max_wait_seconds=300 # 5 minutes
wait_interval=5
elapsed_wait=0

# Wait for the status file to appear
while ! [ -f "${status_file_path}" ]; do
    if [ $elapsed_wait -ge $max_wait_seconds ]; then
        echo "‚ùå Error: Timed out waiting for Kafka readiness signal (${status_file_path}) after ${max_wait_seconds}s."
        echo "   Check the logs of the 'k8s-sandbox' container:"
        ${COMPOSE_CMD} -f compose.yml logs k8s-sandbox
        # Cleanup will run automatically via trap EXIT
        exit 1
    fi
    if [ $((elapsed_wait % 30)) -eq 0 ]; then # Print message every 30 seconds
        echo "   Still waiting for Kafka readiness (${elapsed_wait}s / ${max_wait_seconds}s)..."
        # Add extra debug info:
        echo "   Checking for file: ${status_file_path}"
        if [ -d "${STATUS_DIR}" ]; then
           echo "   Status directory (${STATUS_DIR}) exists. Contents:"
           ls -la "${STATUS_DIR}" || echo "   (Could not list status directory)"
        else
           echo "   Status directory (${STATUS_DIR}) does NOT exist."
        fi
    fi
    sleep $wait_interval
    elapsed_wait=$((elapsed_wait + wait_interval))
done

echo "‚úÖ Kafka cluster reported as ready via ${status_file_path}."

# --- Post-Startup Information ---
echo
echo "üéâ Kafka Throughput Demo is running!"
echo "   - Kafka Broker (via k8s-sandbox port-forward): localhost:9092"
echo "   - Producer, Consumer, Overseer, and Vibectl Agent are running in containers."
echo "   - Shared status volume mounted at './status-volume/'"
echo
echo "‚ÑπÔ∏è Monitoring:"
echo "   - View container logs: ${COMPOSE_CMD} -f compose.yml logs -f <service_name> (e.g., k8s-sandbox, producer)"
echo "   - View Vibectl agent actions: ${COMPOSE_CMD} -f compose.yml logs -f k8s-sandbox | grep 'vibectl auto'"
echo "   - Check latency file: cat ./status-volume/latency.txt"
echo
echo "üõë To stop the demo and clean up resources, press Ctrl+C."

# Keep the script running until interrupted, so the trap can clean up.
# Alternatively, if running everything detached, we could exit here.
# Let's keep it running to show logs and allow Ctrl+C cleanup.
echo "(Press Ctrl+C to stop and clean up)"
# Wait indefinitely
sleep infinity
