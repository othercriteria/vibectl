# Vibectl Bootstrap Demo Structure

This directory contains a bootstrap demo showcasing vibectl's capabilities using a self-contained Kubernetes environment with Ollama as the LLM provider.

## Key Files

- `launch.sh`: Main entry script that sets up the Docker environment and runs the entire demo
  - Detects Docker GID
  - Configures environment variables (all defaults are set in this script)
  - Handles source vs. stable installation options
  - Starts the container
  - Waits for container to become healthy
  - Provides summary output and invites the user to run demo-commands.sh
- `bootstrap-entrypoint.sh`: Script executed inside the container to initialize K3d and Ollama environment
  - Installs vibectl (from source or stable packages)
  - Creates K3d cluster
  - Deploys Ollama via Helm
  - Configures vibectl
  - Sets up status monitoring
- `demo-commands.sh`: Script to run a guided demonstration of vibectl's capabilities after the environment is up
- `Dockerfile`: Container definition for the bootstrap environment
- `Dockerfile.ollama-model`: Used to pre-pull and bake the requested Ollama model into the image
- `cleanup.sh`: Script to clean up resources when done
- `README.md`: User documentation for the bootstrap demo
- `STRUCTURE.md`: This file, documenting component structure
- `.gitignore`: Ignores temporary Compose files and other generated cruft

## Dynamic Files

- `vibectl-compose-*.yml`: Temporary Docker Compose files generated by launch.sh for each run. These are ignored by git via `.gitignore`.

## Architecture

The bootstrap demo operates as a single container in an isolated Docker network:

1. **Bootstrap Container**: Creates a K3d Kubernetes cluster and sets up Ollama
   - Runs K3d with a minimal cluster configuration
   - Deploys Ollama with a smaller LLM model via Helm
   - Configures vibectl to use the Ollama instance
   - Uses health checks to verify component readiness

2. **Demo Automation**: The `launch.sh` script handles the entire demo lifecycle
   - Starts the container with appropriate configuration
   - Waits for all components to initialize
   - Provides instructions for running demonstration commands

3. **Installation Options**:
   - **Source Installation**: Installs vibectl directly from the mounted repository (default)
   - **Stable Installation**: Installs vibectl from PyPI with specific versions (optional)

## Implementation Details

### K3d Cluster

- Minimal Kubernetes cluster with a single node
- Resource limits to ensure it runs on most systems
- Health checks to verify cluster readiness

### Ollama Deployment

- Runs as a Kubernetes Deployment in the "ollama" namespace (via Helm)
- Uses persistent storage for model files (if enabled)
- Exposed via ClusterIP service
- Accessed via port-forward from bootstrap-entrypoint.sh
- Configured with a smaller model for faster startup
- Health checks ensure model is loaded and ready

### Vibectl Configuration

- Vibectl installed in the container environment (source or stable)
- Configured to use the Ollama instance via port-forward
- Environment setup for proper vibectl operation
- **Automatic model aliasing:** The demo ensures that any `OLLAMA_MODEL` value (including those with dots, colons, underscores, etc.) is always available as an alias in `llm`, regardless of normalization. This prevents 'Unknown model' errors due to alias mismatches. The aliasing logic is handled in `bootstrap-entrypoint.sh` after Ollama is ready and before vibectl is configured.
- Verification steps ensure vibectl can connect to Ollama

### Demonstration Flow

The demo showcases several vibectl capabilities in a single automated flow:

1. **Environment Verification**: Ensures all components are working correctly
2. **Basic LLM Functionality**: Verifies vibectl can communicate with Ollama
3. **Kubernetes Analysis**: Uses vibectl to analyze the Ollama deployment
4. **Improvement Suggestions**: Shows how vibectl can suggest improvements to the deployment

## Interface with Main Project

This demo showcases vibectl's capabilities by:

- Providing a self-contained environment that requires minimal setup
- Demonstrating how vibectl can work with local LLMs like Ollama
- Showing how vibectl can analyze and improve Kubernetes deployments
- Supporting both source installation and stable package installation

## Configuration

The bootstrap demo can be configured with the following environment variables (all defaults are set in launch.sh unless otherwise noted):

- `OLLAMA_MODEL`: Model to use for Ollama (defaults to tinyllama)
- `DOCKER_GID`: Docker group ID for socket access (auto-detected)
- `K3D_CLUSTER_NAME`: Name for the K3d cluster (defaults to vibectl-demo)
- `RESOURCE_LIMIT_CPU`: CPU limit for Ollama container. If not set, it is dynamically determined at runtime as 75% of available CPU cores (minimum 1), which is more sensible than a static value.
- `RESOURCE_LIMIT_MEMORY`: Memory limit for Ollama container (defaults to 6Gi)
- `USE_STABLE_VERSIONS`: Whether to use stable PyPI versions (defaults to false)
- `VIBECTL_VERSION`: Version of vibectl to install when using stable versions (defaults to 0.5.0)
- `LLM_VERSION`: Version of LLM to install when using stable versions (defaults to 0.24.2)
